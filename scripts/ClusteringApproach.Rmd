---
title: "Classification - Part 1"
author: "Evan Batzer"
date: "September 3, 2018"
output:
  html_document:
    df_print: paged
  prettydoc::html_pretty:
  highlight: github
fig_width: 6 
fig_height: 4
---

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse); library(testthat); library(vegan); library(msm); library(NbClust)
library(ggplot2); library(cluster); library(mclust); library(indicspecies); library(gganimate)

# Cover data (wide format)
cover <- read.csv("../data/comdata_wideformat.csv", 
                  header = TRUE, 
                  stringsAsFactors = FALSE)
group_percents = cover[,8:19]
cover = cover[,-(8:19)]
comp.attr <- cover[,1:15]
comp.cover <- cover[,15:ncol(cover)]

# Treatment labels and group structure
trtlabels <- read.csv("../data/trtlabels.csv",
          header = TRUE,
          stringsAsFactors = FALSE)

# Species treatments
waps.specs <- read.csv("../data/WAPSspecies.csv",
                       header = TRUE,
                       stringsAsFactors = FALSE)

# Climate data
climate <- read.csv("../data/cimis_monthly.csv",
                       header = TRUE,
                       stringsAsFactors = FALSE)

```

# Clustering Communities - How best to define different states?

There are a number of different algorithms that can be used in cluster analysis, 
ranging from hierarchical, agglomerative methods that have been (in my
impression) a mainstay in Ecology, to more computationally intensive or statistically
nuanced methods, such as K-means (and its variations) or model-based clustering.

Based on my reading, there is no simple way to determine what type of algorithm
is best suited to your needs, or how many clusters are appropriate. According
to Legendre and Legendre (2008), all methods are valid, save for TWINSPAN, which
is cautioned against. If using K-means or hierarchical methods, there are some 
heuristics that can be used to identify the appropriate amount of clusters 
needed in the data. Model-based clustering is more complicated, but offers 
standard metrics to compare model fits -- typically, Bayesian Information 
Criterion (BIC). 

I think the best way to choose an appropriate classification algorithm is to 
explore a number of possibilities. Stein et al. (2016) and Bagchi et al. (2013) 
both employ hierarchical clustering algorithms - flexible beta and Ward's D, 
respectively - but we may have better luck using a method like K-means or 
one of the model-based clusters.

Some key considerations:

* __How to transform data prior to analysis?__ I think in most cases, focusing on the
proportional abundance of species in each sample makes the most sense, but there
may be some validity to using one of the other recommended transformations, such 
as Hellinger or Chi-Square.

* __What distance metric to use?__ Most ecological data utilizes Bray-Curtis or 
Euclidean distances between communities with abundance data. Bray-Curtis has a 
number of poor mathematical properties, however, that may make its use 
problematic in some circumstances. Horn and Morisita-Horn indices may be better,
but are more suited to individual counts an are less often used in circumstances
with cover data.

* __When to start clustering?__ The seeded communities contain a number of species 
that are not well-represented in the data after the first year of planting. While
this is interesting information, it can be problematic for clustering, as it may make
the first year of data really distinct, almost a separate cluster in itself. My
guess is that Stein et al. (2016) found that this was the case with their data - 
they had 5 years of data in their study, but appeared to only run classification
and NMDS on the last 4 years. 

* __What species to include in analyses?__ When trying to cluster communities,
most analyses are conducted on either a relevant subset of species or a modified 
dataset. Stein et al. (2016) combine all of their weedy species / forbs into a 
single column called "forbs", while Bagchi et al. (2013) focus on species that 
occur in at least 2% of all samples taken. There are a lot of weedy species in 
the WAPS data that could be ignored in clustering as "noise".

    * __Here, I've only included non-agricultural weeds in my analysis, which 
    represents roughly 93% of the total cover in the dataset__

```{r, echo = FALSE, warning = FALSE, message = FALSE}
selected.trts <-c("annuals", "WAPS", "Natives", "natives+WAPS+annuals", "annuals+natives", "WAPS+annuals", "WAPS+natives")
selected.clips <- c("none")
selected.fert <- c("none")
selected.water <- c("control", "wet", "latewet", "dry") 

comp.subset = comp.cover[comp.attr$water %in% selected.water &
             comp.attr$sp.trt %in% selected.trts &
             comp.attr$clip %in% selected.clips &
             comp.attr$fertilization %in% selected.fert,]

print("Total Cover in Dataset:")
specsbycover = sort(round(colSums(comp.subset) / sum(comp.subset),2), decreasing = TRUE)
# specsbycover

print("Plot Occupancy in Dataset:")
specsbyfreq = sort(round(colSums(decostand(comp.subset, method = "pa")) / nrow(comp.subset), 2), decreasing = TRUE)
# specsbyfreq
```


```{r, echo = FALSE, warning = FALSE, message = FALSE}
# What treatments and years should be selected?
selected.trts <-c("annuals", "WAPS", "Natives", "natives+WAPS+annuals", "annuals+natives", "WAPS+annuals", "WAPS+natives")
selected.clips <- c("none")
selected.fert <- c("none")
selected.water <- c("control") 
selected.years <- c(2008:2018)

# To include all treatments:
# selected.water <- c("control", "wet", "latewet", "dry") 

# Subsetting cover matrix
ord.mat <- comp.cover[comp.attr$water %in% selected.water &
                     comp.attr$sp.trt %in% selected.trts &
                     comp.attr$clip %in% selected.clips &
                     comp.attr$fertilization %in% selected.fert &
                      comp.attr$year %in% selected.years,]

# Subsetting attribute matrix
ord.att <- comp.attr[comp.attr$water %in% selected.water &
                     comp.attr$sp.trt %in% selected.trts &
                     comp.attr$clip %in% selected.clips &
                     comp.attr$fertilization %in% selected.fert &
                      comp.attr$year %in% selected.years,]

# Checking that these datasets are the same size
expect_true(nrow(ord.att) == nrow(ord.mat))

# Filtering species
totalcov = sum(ord.mat)
toselect = waps.specs$specname[waps.specs$group %in% c("annual", "natives", "waps")]
ord.mat = ord.mat %>% select(toselect)
cat("Fraction of total cover contained in subset =", sum(ord.mat) / totalcov)

# A number of rows have  no recorded live plants (mostly dry treatments?)
ord.att <- ord.att[rowSums(ord.mat) != 0, ]
ord.mat <- ord.mat[rowSums(ord.mat) != 0, ]
```

# Visualizing Data:

Raw functional group abundances:

```{r}
sumtable = left_join(ord.att, bind_cols(comp.attr,group_percents)) %>%
  group_by(plot, year, sp.trt) %>%
  select(annuals, natives, waps) %>%
  mutate(total = sum(annuals, natives, waps)) %>%
  group_by(year, sp.trt) %>%
  summarise(annprop = mean(annuals / total),
            natprop = mean(natives / total),
            wapsprop = mean(waps / total),
            annsem = sd(annuals / total) / sqrt(n()),
            natsem = sd(natives / total) / sqrt(n()),
            wapssem = sd(waps / total) / sqrt(n()))
  
sumtable %>%
  ggplot(aes(x = year)) +
  geom_line(aes(y = annprop), color = "red") +
  geom_line(aes(y = natprop), color = "green") +
  geom_line(aes(y = wapsprop), color = "blue") +
  geom_errorbar(aes(ymin = annprop - annsem,
                    ymax = annprop + annsem),
                color = "red",
                width = .1) +
  geom_errorbar(aes(ymin = natprop - natsem,
                    ymax = natprop + natsem),
                color = "green",
                width = .1) +
  geom_errorbar(aes(ymin = wapsprop - wapssem,
                    ymax = wapsprop + wapssem),
                color = "blue",
                width = .1) +
  xlab("Year") +
  ylab("Proportional Abundance")+
  facet_wrap(~sp.trt, nrow = 4)

ggsave("../figures/ProportionalAbundances.pdf", width = 10, height = 6)
```


The first step in this analysis is to visualize the data using some sort of
unconstrained ordination method. Because I'll be using Bray-Curtis distance to 
describe differences between points, NMDS seems to be the best option. 

Below, I show an NMDS plot of all community datapoints, colored by year. I believe
that I've sent these graphs along before -- the basic gist I get from this figure 
is that communities aren't particularly stable.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
# Constructing distance matrix and running NMDS
distmat <- vegdist(decostand(ord.mat, "total"), method = "bray")
WAPS.mds <- metaMDS(distmat, try = 1, trymax = 5, trace = F, autotransform = TRUE)
MDS_xy <- bind_cols(data.frame(ord.att), data.frame(X = WAPS.mds$points[,1], Y = WAPS.mds$points[,2]))

# Plotting figure
ggplot(MDS_xy, aes(X1, Y)) + 
  geom_point(aes(color = as.factor(year))) + 
  theme_bw() +
  geom_text(data = data.frame(X1 = Inf, Y = -Inf), 
            hjust = 1, vjust = -1, 
            label = paste("Stress =", round(WAPS.mds$stress, 2)))

p = ggplot(MDS_xy, aes(X1, Y)) + 
  geom_point(aes(color = as.factor(sp.trt)), size = 2) + 
  theme_bw() +
  geom_text(data = data.frame(X1 = Inf, Y = -Inf), 
            hjust = 1, vjust = -1, 
            label = paste("Stress =", round(WAPS.mds$stress, 2))) +
  labs(title = 'Year: {frame_time}') +
  transition_time(year) +
  ease_aes('linear')

# animate(p, detail = 40, fps = 10)
```

# K-means Clustering

To be able to quantitatively assess differences between communities when there 
isn't a clear pattern with simple similarity metrics, clustering methods may ease
comparison. In this method, rather than looking at distances between communities,
we can compare changes in community composition as movement between discrete states.

Here, I'm employing K-means clustering, one method that attempts to partition
datasets into some "K" number of cluster types. One nice feature of this method
is that the optimal number of clusters can be determined by a number of different 
metrics.

## Selecting an appropriate number of clusters

Here, I utilize a package called NbClust() that can be used to implement a number
of different metrics -- the nbclust() package in R suggests using a battery of 
tests to see if some cluster number appears as a consistent good performer.

```{r, include = FALSE}
counter = 1
groupdiss <- c()
groupsil <- c()
for(i in 2:10){
  tempclust = pam(distmat, i)
  groupdiss[counter] = mean(tempclust$clusinfo[,3])
  groupsil[counter] = tempclust$silinfo$avg.width
  counter <- counter + 1
}

data.frame(k = c(2:10), dis = groupdiss, sil = groupsil) %>% 
  ggplot(aes(x = k,
             y = groupsil,
             fill = groupsil == max(groupsil))) +
  geom_point(size = 3, pch = 21)

data.frame(k = c(2:10), dis = groupdiss, sil = groupsil) %>% 
  ggplot(aes(x = k,
             y = groupdiss,
             fill = groupsil == max(groupsil))) +
  geom_point(size = 3, pch = 21)
```

When comparing a number of different criteria, 4 seems to be the best number of clusters to use
(see best.nc table, which highlights the best performer for each type of metric). 
4 clusters is selected as the best number in 4 of the 8 metrics,
and consistently performs well (usually in the top 2-4 of the 10) for the rest.

Apparently, 7 clusters also seems like a good second choice by these metrics,
though that number seems too high to be relevant given the number of replicates 
we have, as well as my intuition for the system as a whole. 

```{r, echo = FALSE, warning = FALSE, message = FALSE}
bestclust = NbClust(decostand(ord.mat, method = "total"), min.nc = 2, max.nc = 10, method = "kmeans",
        index = c("hartigan", "ch", "beale", "kl", "cindex", "db", "silhouette", "duda", "gap"))[1:2]


res = get_clust_tendency(decostand(ord.mat, method = "total"), 100, graph = TRUE)
# Significant clusterability, H = 0.1
```

## Visualizing how the clustering algorithm splits up the data

```{r, echo = FALSE, warning = FALSE, message = FALSE}
k.cluster = pam(distmat, 4)
k.cluster$objective
MDS_xy$clust = k.cluster$clustering

ggplot(MDS_xy, aes(X1, Y, color = as.factor(clust))) + 
  geom_point() + 
  theme_bw() +
  geom_text(data = data.frame(X1 = Inf, Y = -Inf), 
            aes(color = NULL), hjust = 1, vjust = -1, 
            label = paste("Stress =", round(WAPS.mds$stress, 2))) +
  ggtitle("NMDS colored by cluster")

cluscounts = bind_cols(ord.att, data.frame(cluster = k.cluster$clustering)) %>% group_by(year, cluster) %>% summarise(count = n()) %>% bind_rows(data.frame(year = 2008, cluster = 4, count = 0))
  
cols = rainbow(4, v = .75)

ggplot(cluscounts, 
       aes(x = year, 
           y = count / 96, 
           fill = factor(cluster),
           group = factor(cluster),
           shape = factor(cluster))) + 
  geom_point(stat = "identity", size = 3) +
  geom_line(stat = "identity", color = "black", linetype = 2) +
  ggtitle("State Assignment Frequency") +
  theme_bw() + 
  ylab("Frequency") +
  xlab("Year") +
  scale_x_continuous(breaks = seq(2008, 2018, by = 2)) +
  scale_fill_manual(name = 'State Assignment', 
         values =c("1" = cols[1], 
                   "2" = cols[2], 
                   "3" = cols[3], 
                   "4" = cols[4]),
         labels = c('E. glaucus - S. pulchra',
                    'F. perennis - B. hordeaceous', 
                    'E. caput-medusae - A. triuncialis',
                    'A. fatua - B. diandrus')) +
  scale_shape_manual(name = 'State Assignment', 
         values = c(21,22,23,24),
         labels = c('E. glaucus - S. pulchra',
                    'F. perennis - B. hordeaceous', 
                    'E. caput-medusae - A. triuncialis',
                    'A. fatua - B. diandrus'))

ggsave("../figures/assignmentfrequency.pdf", width = 7, height = 4)
```

# Describing clusters:

## Indicator species analysis:

What defines each cluster? The few papers I have seen describing this method
have used indicator species analysis to determine what defines each group --
I've done the same below:

```{r, echo = FALSE}
IS = multipatt(decostand(ord.mat, method = "total"), k.cluster$clustering, duleg = TRUE, control = how(nperm=999))
summary(IS, alpha = .05)
```

The four groups defined seem to indicate the presence of a few different
species groups that I've roughly defined as the following: 

1. Native species   

2. "Wet annuals" -- those annuals that seemed to do best early in the experiment,
either driven by wetter temperatures or priority effects.  

3. "WAPS"   

4. "Dry annuals" -- those annuals that seemed to do best later in the experiment,
perhaps driven by drier weather.  

## Visualizing differences

What constitutes each group? The easiest way to do so might be a simple pie chart:

```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.height = 10, fig.width = 10}
piecharts = bind_cols(data.frame(cluster = k.cluster$clustering), ord.mat)
piecharts$cluster[piecharts$cluster == 1] = "Natives"
piecharts$cluster[piecharts$cluster == 2] = "Wet Annuals"
piecharts$cluster[piecharts$cluster == 3] = "WAPS"
piecharts$cluster[piecharts$cluster == 4] = "Dry Annuals"

piecharts %>%
  gather(key = "species", value = "cover", -cluster) %>%
  group_by(cluster, species) %>%
  summarise(cover = mean(cover)) %>%
  ggplot(aes(x = "", y = cover, fill = species))+
  geom_bar(stat = "identity", position = position_fill(), color = "black") +
  # geom_text(aes(label = Cnt), position = position_fill(vjust = 0.5)) +
  coord_polar(theta = "y") +
  facet_wrap(~cluster) +
  theme(axis.title.x = element_blank(), axis.title.y = element_blank(),  axis.ticks = element_blank(),
        panel.grid  = element_blank(), axis.text = element_blank(), legend.title = element_blank()) +
  theme(legend.position='bottom') + guides(fill=guide_legend(nrow=2,byrow=TRUE)) +
  theme(strip.text.x = element_text(size = 20, face = "bold"))
```

# Plotting transitions between clusters over time

```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.height = 10, fig.width = 14}
clustdat <- bind_cols(ord.att, data.frame(cluster = k.cluster$clustering)) %>%
  dplyr::arrange(sp.trt, plot)

# Assigning states
clustdat$cluster[clustdat$cluster == 1] = "Natives"
clustdat$cluster[clustdat$cluster == 2] = "Wet Annuals"
clustdat$cluster[clustdat$cluster == 3] = "WAPS"
clustdat$cluster[clustdat$cluster == 4] = "Dry Annuals"

# Plotting change in assignment over time
clustdat$plot <- factor(clustdat$plot, levels = unique(clustdat$plot))
clustdat %>% ggplot(aes(x = year,
           y = as.numeric(plot) - .5)) +
  theme_bw() + 
  geom_tile(color = "black", aes(fill = as.factor(cluster))) +
  geom_hline(yintercept = c(seq(0, 56, by = 8)), size = 2) +
  geom_text(label = unique(clustdat$sp.trt),
            data = data.frame(year = rep(2006, 7),
                              plot = seq(4, 52, by = 8)),
            fontface = "bold") +
  xlim(2005, 2019)
```

# Frequency of transitions

How often do transitions occur? The above figures show that there are some general
patterns in transition frequency and directionality of change. It seems that 
transitions to WAPS are the most frequent early in the experiment, but many
groups transition to a "dry annuals" state following the drought.  

To assess this qualitatively, I've included some figures with transition
frequency + direction plotted with precipitation.

In the first figure, total annual precipitation (relative) is plotted as a black
line above the plot.

In the second, total precipitation, early (Oct - Dec, blue line), middle (Jan - 
Mar, orange line), and late (April - May, red line) precip are plotted as 
separate lines above the bars.

```{r, echo = FALSE, warning = FALSE, message = FALSE}
next_state = clustdat %>% mutate(year = year + 1) %>% rename(paststate = cluster)
transitions = left_join(clustdat, next_state, by = c("plot", "year")) %>% 
  mutate(transition = as.numeric(!cluster == paststate))

transto = transitions %>% filter(transition == 1) %>% group_by(cluster, year) %>% 
  summarise(total = sum(transition))

climate$month = gsub("-.*", "", climate$Month.Year)

climsum = climate %>% group_by(Water.Year) %>% 
  summarise(total = sum(Total.Precip..mm.), 
            early = sum(Total.Precip..mm.[month %in% c("Oct", "Nov", "Dec")]),
            mid = sum(Total.Precip..mm.[month %in% c("Jan", "Feb", "March")]),
            late = sum(Total.Precip..mm.[month %in% c("April", "May")]))

transitions %>% group_by(year) %>% filter(year != 2008) %>%
  summarise(trans = sum(na.omit(transition))) %>%
  ggplot() +
  geom_bar(aes(x = year,
             y = trans / 56),
           stat = "identity",
           color = "black", 
           fill = "forestgreen") +
  geom_line(data = climsum %>% filter(Water.Year > 2007),
            aes(x = Water.Year ,
                y = total / max(na.omit(total)))) +
  ylab("Proportion of plots transitioned")

transto %>%
  ggplot() +
  geom_bar(aes(x = year,
             y = total / 56,
             fill = cluster),
           stat = "identity",
           color = "black")+
  geom_line(data = climsum %>% filter(Water.Year > 2007),
            aes(x = Water.Year,
                y = total / max(na.omit(total)) + 1)) +
    geom_line(data = climsum %>% filter(Water.Year > 2007),
            aes(x = Water.Year,
                y = early / max(na.omit(total)) + 1),
            color = "blue") +
    geom_line(data = climsum %>% filter(Water.Year > 2007),
            aes(x = Water.Year,
                y = mid / max(na.omit(total)) + 1),
            color = "orange") +
    geom_line(data = climsum %>% filter(Water.Year > 2007),
            aes(x = Water.Year,
                y = late / max(na.omit(total)) + 1),
            color = "red") +
  geom_hline(yintercept = 1) +
  ylab("Proportion of plots transitioned")
```

```{r, include = FALSE}
# Writing new CSV with cluster data:

clustdat <- bind_cols(ord.att, data.frame(cluster = k.cluster$clustering)) %>%
  dplyr::arrange(sp.trt, plot)

#write.csv("../data/WAPSclusters.csv", x = clustdat)
```

# Change per transition

```{r}

x = bind_cols(clustdat,ord.mat)
i = 2
transbray = function(x){
  
  output <- data.frame(trans = NULL, dis = NULL, year = NULL)
  
  for(i in 1:nrow(x)){
    if(i != 1){
      trans = if_else(x$cluster[x$year == x$year[i]] == x$cluster[x$year == x$year[i - 1]], 0, 1)
      
      spmat = x %>% filter(year %in% c(x$year[i], x$year[i-1])) %>% select(colnames(ord.mat))
      dis = vegdist(decostand(spmat, "total"),
                    method = "bray",
                    diag = FALSE)[1]
      year = x$year[i]
      output = bind_rows(output, data.frame(trans, dis, year))    
    }
    
  }
  
  return(output)
}


bind_cols(clustdat,ord.mat) %>%
  group_by(plot) %>%
  do(transbray(.)) %>%
  ggplot(aes(x = dis, fill = as.factor(trans))) +
  geom_density(position = position_dodge(), alpha = .2)
  
braytrans = bind_cols(clustdat,ord.mat) %>%
  group_by(plot) %>%
  do(transbray(.)) 
braytrans = na.omit(braytrans)

quantile(braytrans$dis[braytrans$trans == 1])
quantile(braytrans$dis[braytrans$trans == 0])
``` 

# Net change in desired indicator species per transition assignment

```{r}
istable = IS$sign

grp1 = rownames(na.omit(istable[istable$s.1 == 1,]))
grp2 = rownames(na.omit(istable[istable$s.2 == 1,]))
grp3 = rownames(na.omit(istable[istable$s.3 == 1,]))
grp4 = rownames(na.omit(istable[istable$s.4 == 1,]))

transbray = function(x){
  
  output <- data.frame(trans = NULL, dis = NULL, year = NULL)
  
  for(i in 1:nrow(x)){
    if(i != 1){
      state = x$cluster[x$year == x$year[i]]
      prev = x$cluster[x$year == x$year[i - 1]]
      
      spmat = x %>% 
        filter(year %in% c(x$year[i], x$year[i-1])) %>% 
        arrange(year, .by_group = FALSE) %>%
        select(colnames(ord.mat))
      
      tot = rowSums(spmat)
      
      delta_g1 = diff(rowSums(spmat %>% select(grp1)) / tot)
      delta_g2 = diff(rowSums(spmat %>% select(grp2)) / tot)
      delta_g3 = diff(rowSums(spmat %>% select(grp3)) / tot)
      delta_g4 = diff(rowSums(spmat %>% select(grp4)) / tot)
      
      g1_tot = c(rowSums(spmat %>% select(grp1)) / tot)[2]
      g2_tot = c(rowSums(spmat %>% select(grp2)) / tot)[2]
      g3_tot = c(rowSums(spmat %>% select(grp3)) / tot)[2]
      g4_tot = c(rowSums(spmat %>% select(grp4)) / tot)[2]

      year = x$year[i]
      output = bind_rows(output, data.frame(state, prev, year, 
                                            delta_g1, delta_g2, delta_g3, delta_g4,
                                            g1_tot, g2_tot, g3_tot, g4_tot))    
    }
    
  }
  
  return(output)
  
}

grpchange = bind_cols(clustdat,ord.mat) %>%
  group_by(plot) %>%
  do(transbray(.))

all = inner_join(clustdat, grpchange, by = c("plot", "year"))
all = na.omit(all)
min(all$g4_tot[all$state == 4])
min(all$g3_tot[all$state == 3])
min(all$g2_tot[all$state == 2])
min(all$g1_tot[all$state == 1])

na.omit(grpchange) %>% 
  mutate(trans = as.numeric(state != prev)) %>%
  filter(trans == 1) %>%
  group_by(state) %>%
  summarise(g1 = mean(delta_g1),
            g2 = mean(delta_g2),
            g3 = mean(delta_g3),
            g4 = mean(delta_g4))

mean(.11, .06, .04, .19)
```

```{r}
piecharts = bind_cols(data.frame(cluster = k.cluster$clustering), ord.mat) %>%
  mutate(g1_cov = nassella + bro.carinatus + elymus + lupinus + vulpia,
         g2_cov = bro.hordeaceous + lolium + trifolium,
         g3_cov = aegilops + taeniatherum,
         g4_cov = avena + bro.diandrus) %>%
  select(cluster, g1_cov, g2_cov, g3_cov, g4_cov)

piecharts=piecharts %>% 
  arrange(cluster) %>%
  mutate(total= g1_cov + g2_cov + g3_cov + g4_cov)
  
write.csv(x = piecharts, "covdat.csv")
```

